import os
import re
import json
import argparse
import shutil
from collections import defaultdict

# ========== å‚æ•°è§£æ ==========
parser = argparse.ArgumentParser()
parser.add_argument("--base", required=True, help="åŸå§‹ .lproj èµ„æºç›®å½•")
parser.add_argument("--target", required=False, help="è¿½åŠ  JSON çš„ç›®æ ‡ç›®å½•")
parser.add_argument("--a", action="store_true", help="æ˜¯å¦å°†ç»“æœè¿½åŠ åˆ°ç›®æ ‡ JSON")
args = parser.parse_args()

base_dir = args.base
target_append_dir = args.target
should_append = args.a

source_locale = "zh-Hans.lproj"
output_dir = os.path.join(os.getcwd(), "lproj-json")
log_output_path = os.path.join(output_dir, "translation_log.txt")

# ==== å¯åŠ¨æ—¶æ¸…ç† lproj-json æ–‡ä»¶å¤¹ï¼Œå¦‚æœ translation_log.txt å­˜åœ¨ ====
if os.path.exists(log_output_path):
    print(f"æ£€æµ‹åˆ°ä¹‹å‰çš„æ—¥å¿—æ–‡ä»¶ {log_output_path}ï¼Œå¼€å§‹åˆ é™¤æ•´ä¸ª {output_dir} æ–‡ä»¶å¤¹...")
    shutil.rmtree(output_dir)
    print(f"å·²åˆ é™¤ {output_dir} æ–‡ä»¶å¤¹ï¼Œå‡†å¤‡é‡æ–°ç”Ÿæˆå†…å®¹")

# ===== æ˜ å°„è¡¨ =====
mapping_raw = """
ar
as
az
be
bg-BG:bg
bn-IN:bn
bn
bo
bs
ca
cs
da
de
el
en-AU
en-GB
en-IN
en:en-US
es-419:es
es-MX:es
es
et
eu
fa
fi
fr
gl
gu-IN:gu
ha
he-IL:he
he
hi
hr
hu
hy-AM:hy
id
is
it
ja
ka
kk
km
kn
ko
lo
lt
lv
mk
ml-IN:ml
mr
ms
mt
my
nb
ne-IN:ne
ne-NP:ne
nl
or
pa-IN:pa
pl
pt-BR
pt-PT
ro
ru
sk
sl
sq
sr
sv
sw
ta
te
th
tr
ug
uk
ur-IN
ur-PK
uz
vi
zh-Hans:zh-CN
zh-Hant-HK:zh-HK
zh-Hant:zh-HK
"""

key_override_map = {
    "è¿åŠ¨": "sport.tabName",
    "æˆ·å¤–è·‘æ­¥": "sport.entry.outdoorRunning",
    "å¥èµ°": "sport.entry.outsideWalking",
    "æˆ·å¤–éª‘è¡Œ": "sport.entry.outsideRiding",
    "å®¤å†…è·‘æ­¥": "sport.entry.indoorRunning",
    "è·³ç»³": "sport.entry.ropeSkipping",
    "è¿åŠ¨è®°å½•": "sport.plan.sportRecord",
    "å…¨éƒ¨": "all.title",
    "æš‚æ— è¿åŠ¨è®°å½•": "sport.plan.noRecord",
    "è®­ç»ƒæŒ‡æ ‡": "sport.plan.trainingIndicator",
    "æ‰«ä¸€æ‰«": "sport.plan.scanQRCode",
    "æ·»åŠ è®¾å¤‡": "sport.plan.addDevice",
    "åŠ¨æ„Ÿå•è½¦": "sport.entry.indoorBicycle"
}
target_values = list(key_override_map.keys())

def ensure_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)

def parse_strings_file(filepath):
    translations = {}
    if not os.path.exists(filepath):
        return translations
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
        matches = re.findall(r'"(.*?)"\s*=\s*"(.+?)";', content)
        for key, value in matches:
            translations[key] = value
    return translations

mapping = {}
for line in mapping_raw.strip().splitlines():
    line = line.strip()
    if not line:
        continue
    if ':' in line:
        k, v = line.split(':', 1)
        mapping[k] = v
    else:
        mapping[line] = line

# ===== åˆå§‹åŒ– =====
ensure_dir(output_dir)
log_lines = []

def log(msg):
    print(msg)
    log_lines.append(msg)

# ===== Step 1: è§£ææºè¯­è¨€ zh-Hans.lproj =====
source_file = os.path.join(base_dir, source_locale, "Localizable.strings")
source_map = parse_strings_file(source_file)
reverse_source_map = defaultdict(list)
for k, v in source_map.items():
    reverse_source_map[v].append(k)

value_to_key_map = {}
initial_key_list = []
log("\nğŸ” Step 1: ä» zh-Hans.lproj åå‘æŸ¥æ‰¾ç›®æ ‡valueå¯¹åº”çš„keyå’Œå¤‡é€‰key")
for val in target_values:
    keys = reverse_source_map.get(val)
    if keys:
        main_key = keys[0]
        fallback_keys = keys[1:]
        initial_key_list.append(main_key)
        value_to_key_map[main_key] = {"value": val, "fallback_keys": fallback_keys}
        log(f"  âœ… \"{val}\" => ä¸»key: {main_key}ï¼Œå¤‡é€‰key: {fallback_keys}")
    else:
        log(f"  âŒ \"{val}\" æœªæ‰¾åˆ°å¯¹åº”key")

# ===== Step 2: å¤šè¯­è¨€åŒ…ç¿»è¯‘æŸ¥æ‰¾ =====
translations_all = defaultdict(dict)
missing_keys_log = defaultdict(list)
processed_json_targets = set()
lproj_folders = [d for d in os.listdir(base_dir) if d.endswith('.lproj') and d != source_locale]

for folder in sorted(lproj_folders):
    locale_code = folder[:-6]
    json_target = mapping.get(locale_code, locale_code)
    if json_target in processed_json_targets:
        continue

    lproj_path = os.path.join(base_dir, folder, "Localizable.strings")
    if not os.path.exists(lproj_path):
        continue

    locale_map = parse_strings_file(lproj_path)
    output_json_dict = {}

    for orig_key in initial_key_list:
        val = value_to_key_map[orig_key]["value"]
        fallback_keys = value_to_key_map[orig_key]["fallback_keys"]
        out_key = key_override_map.get(val, orig_key)
        search_keys = [orig_key] + fallback_keys
        trans_val = None
        for k in search_keys:
            if k in locale_map:
                trans_val = locale_map[k]
                break
        if trans_val:
            output_json_dict[out_key] = trans_val
        else:
            missing_keys_log[folder].append(orig_key)

    out_path = os.path.join(output_dir, f"{json_target}.json")
    with open(out_path, 'w', encoding='utf-8') as f:
        json.dump(output_json_dict, f, ensure_ascii=False, indent=2)
    processed_json_targets.add(json_target)

# ===== Step 3: å¯é€‰è¿½åŠ åˆ°å¤–éƒ¨ JSON æ–‡ä»¶ï¼Œå¹¶æ‰“å°æ–°å¢å’Œå·²å­˜åœ¨è¯æ¡ =====
if should_append and target_append_dir:

    def append_to_existing_json(target_append_dir, output_dir):
        for filename in os.listdir(output_dir):
            if not filename.endswith(".json"):
                continue
            src_path = os.path.join(output_dir, filename)
            tgt_path = os.path.join(target_append_dir, filename)

            with open(src_path, 'r', encoding='utf-8') as f:
                new_data = json.load(f)

            if os.path.exists(tgt_path):
                with open(tgt_path, 'r', encoding='utf-8') as f:
                    old_lines = f.readlines()

                try:
                    existing_data = json.loads("".join(old_lines))
                except json.JSONDecodeError:
                    msg = f"âŒ æ— æ³•è§£æ {tgt_path}ï¼Œè·³è¿‡"
                    print(msg)
                    log_lines.append(msg)
                    continue

                # åŒºåˆ†æ–°å¢å’Œå·²å­˜åœ¨çš„ key
                to_add = {k: v for k, v in new_data.items() if k not in existing_data}
                existing_keys = [k for k in new_data.keys() if k in existing_data]

                if not to_add:
                    msg = f"â„¹ï¸ {tgt_path} ä¸­å·²åŒ…å«å…¨éƒ¨è¯æ¡ï¼Œæ— éœ€è¿½åŠ "
                    print(msg)
                    log_lines.append(msg)
                    continue

                # æ‰¾åˆ° { æ‰€åœ¨çš„è¡Œå·
                first_brace_index = None
                for i, line in enumerate(old_lines):
                    if line.strip() == '{':
                        first_brace_index = i
                        break
                if first_brace_index is None:
                    msg = f"âŒ {tgt_path} æ‰¾ä¸åˆ°å·¦èŠ±æ‹¬å· '{{'ï¼Œè·³è¿‡"
                    print(msg)
                    log_lines.append(msg)
                    continue

                # å‘ä¸Šå¯»æ‰¾æœ€åä¸€ä¸ªæœ‰æ•ˆé”®å€¼å¯¹è¡Œï¼ˆéç©ºã€éæ³¨é‡Šã€éèŠ±æ‹¬å·ï¼‰
                last_kv_index = None
                for i in range(len(old_lines) - 1, -1, -1):
                    line_strip = old_lines[i].strip()
                    if (
                        line_strip and
                        not line_strip.startswith("//") and
                        not line_strip.startswith("/*") and
                        not line_strip.startswith("*") and
                        line_strip != "}" and
                        line_strip != "{"
                    ):
                        last_kv_index = i
                        break

                insertion = []
                items = list(to_add.items())
                if last_kv_index is None or last_kv_index <= first_brace_index:
                    # æ–‡ä»¶ä¸ºç©º JSON æˆ–æ— æœ‰æ•ˆé”®å€¼å¯¹ï¼Œç›´æ¥åœ¨ { åæ’å…¥ï¼Œæ— éœ€é€—å·
                    for idx, (k, v) in enumerate(items):
                        line = f'  "{k}": "{v}"'
                        if idx < len(items) - 1:
                            line += ","
                        insertion.append(line + "\n")
                    # æ’å…¥åœ¨ { åé¢ä¸€è¡Œ
                    new_lines = old_lines[:first_brace_index + 1] + insertion + old_lines[first_brace_index + 1:]
                else:
                    # æ–‡ä»¶å·²æœ‰é”®å€¼ï¼Œç¡®ä¿æœ€åä¸€æœ‰æ•ˆè¡Œæœ‰é€—å·
                    if not old_lines[last_kv_index].rstrip().endswith(","):
                        old_lines[last_kv_index] = old_lines[last_kv_index].rstrip() + ",\n"

                    for idx, (k, v) in enumerate(items):
                        line = f'  "{k}": "{v}"'
                        if idx < len(items) - 1:
                            line += ","
                        insertion.append(line + "\n")
                    # æ’å…¥åœ¨æœ€åæœ‰æ•ˆé”®å€¼å¯¹è¡Œä¹‹å
                    new_lines = old_lines[:last_kv_index + 1] + insertion + old_lines[last_kv_index + 1:]

                # å†™å›æ–‡ä»¶
                with open(tgt_path, 'w', encoding='utf-8') as f:
                    f.writelines(new_lines)

                msg = f"âœ… å·²è¿½åŠ  {len(to_add)} é¡¹åˆ° {tgt_path}"
                if existing_keys:
                    msg += f"ï¼Œå·²æœ‰ {len(existing_keys)} é¡¹è¯æ¡æœªè¿½åŠ : {existing_keys}"
                print(msg)
                log_lines.append(msg)

            else:
                # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥å†™æ–°æ–‡ä»¶
                with open(tgt_path, 'w', encoding='utf-8') as f:
                    json.dump(new_data, f, ensure_ascii=False, indent=2)
                msg = f"ğŸ†• åˆ›å»ºå¹¶å†™å…¥æ–°æ–‡ä»¶ {tgt_path}"
                print(msg)
                log_lines.append(msg)

    append_to_existing_json(target_append_dir, output_dir)

# ===== Step 4: å†™å…¥æ—¥å¿—æ–‡ä»¶ =====
ensure_dir(output_dir)
with open(log_output_path, 'w', encoding='utf-8') as logf:
    logf.write("\n".join(log_lines))

print(f"\næ—¥å¿—å†™å…¥å®Œæˆ: {log_output_path}")
